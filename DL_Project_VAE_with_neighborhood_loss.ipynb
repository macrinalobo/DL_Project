{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"JKAj4gPJi95i","outputId":"c07d513f-2f75-428d-8bb3-40a554695966"},"outputs":[{"name":"stderr","output_type":"stream","text":["2024-11-27 18:01:25.982966: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"]}],"source":["import numpy as np\n","import pandas as pd\n","import os\n","import torch\n","from sklearn.model_selection import train_test_split\n","import scanpy as sc\n","from scipy.spatial.distance import cdist\n","from model import *\n","import torch.optim as optim\n","from sklearn.metrics import mean_squared_error\n","from skimage.metrics import structural_similarity as ssim\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hrGBCGWui95j"},"outputs":[],"source":["data_dir = 'spatial_datasets/GSE213264_RAW/'\n","results_dir = 'results_neigh_loss/'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KRT2GMSGi95k","outputId":"68a41d64-acca-4ad4-b486-e97b7b5f7214"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n","Epoch [1/100], Loss: 6254.7686\n","Epoch [2/100], Loss: 5470.3965\n","Epoch [3/100], Loss: 4999.7456\n","Epoch [4/100], Loss: 4509.5044\n","Epoch [5/100], Loss: 4092.1528\n","Epoch [6/100], Loss: 3748.9604\n","Epoch [7/100], Loss: 3441.2361\n","Epoch [8/100], Loss: 3170.8616\n","Epoch [9/100], Loss: 2972.5476\n","Epoch [10/100], Loss: 2776.9275\n","Epoch [11/100], Loss: 2598.2104\n","Epoch [12/100], Loss: 2437.5288\n","Epoch [13/100], Loss: 2301.6252\n","Epoch [14/100], Loss: 2171.8333\n","Epoch [15/100], Loss: 2056.2671\n","Epoch [16/100], Loss: 1962.5521\n","Epoch [17/100], Loss: 1870.1027\n","Epoch [18/100], Loss: 1777.7982\n","Epoch [19/100], Loss: 1694.8459\n","Epoch [20/100], Loss: 1610.7327\n","Epoch [21/100], Loss: 1547.0195\n","Epoch [22/100], Loss: 1479.4385\n","Epoch [23/100], Loss: 1422.4302\n","Epoch [24/100], Loss: 1370.3320\n","Epoch [25/100], Loss: 1321.1257\n","Epoch [26/100], Loss: 1279.3480\n","Epoch [27/100], Loss: 1241.6064\n","Epoch [28/100], Loss: 1208.7111\n","Epoch [29/100], Loss: 1178.7463\n","Epoch [30/100], Loss: 1149.4192\n","Epoch [31/100], Loss: 1128.8276\n","Epoch [32/100], Loss: 1107.2192\n","Epoch [33/100], Loss: 1089.4229\n","Epoch [34/100], Loss: 1070.7435\n","Epoch [35/100], Loss: 1053.6292\n","Epoch [36/100], Loss: 1041.3662\n","Epoch [37/100], Loss: 1027.6536\n","Epoch [38/100], Loss: 1015.3521\n","Epoch [39/100], Loss: 1002.4980\n","Epoch [40/100], Loss: 992.4321\n","Epoch [41/100], Loss: 983.8803\n","Epoch [42/100], Loss: 975.7643\n","Epoch [43/100], Loss: 964.0938\n","Epoch [44/100], Loss: 960.3419\n","Epoch [45/100], Loss: 952.0930\n","Epoch [46/100], Loss: 947.4182\n","Epoch [47/100], Loss: 943.4134\n","Epoch [48/100], Loss: 935.9052\n","Epoch [49/100], Loss: 930.3993\n","Epoch [50/100], Loss: 926.0551\n","Epoch [51/100], Loss: 922.4079\n","Epoch [52/100], Loss: 919.6483\n","Epoch [53/100], Loss: 913.7514\n","Epoch [54/100], Loss: 912.7307\n","Epoch [55/100], Loss: 910.2165\n","Epoch [56/100], Loss: 905.4626\n","Epoch [57/100], Loss: 903.9414\n","Epoch [58/100], Loss: 902.4424\n","Epoch [59/100], Loss: 900.6410\n","Epoch [60/100], Loss: 896.3060\n","Epoch [61/100], Loss: 895.0162\n","Epoch [62/100], Loss: 894.9140\n","Epoch [63/100], Loss: 890.4800\n","Epoch [64/100], Loss: 891.8424\n","Epoch [65/100], Loss: 888.4267\n","Epoch [66/100], Loss: 886.0357\n","Epoch [67/100], Loss: 884.1204\n","Epoch [68/100], Loss: 885.5824\n","Epoch [69/100], Loss: 881.0182\n","Epoch [70/100], Loss: 883.0668\n","Epoch [71/100], Loss: 883.2535\n","Epoch [72/100], Loss: 880.5428\n","Epoch [73/100], Loss: 878.4396\n","Epoch [74/100], Loss: 880.2331\n","Epoch [75/100], Loss: 877.9834\n","Epoch [76/100], Loss: 875.4656\n","Epoch [77/100], Loss: 873.2305\n","Epoch [78/100], Loss: 876.3857\n","Epoch [79/100], Loss: 872.1996\n","Epoch [80/100], Loss: 872.5701\n","Epoch [81/100], Loss: 873.4652\n","Epoch [82/100], Loss: 872.0892\n","Epoch [83/100], Loss: 871.8282\n","Epoch [84/100], Loss: 868.6840\n","Epoch [85/100], Loss: 870.3391\n","Epoch [86/100], Loss: 869.4605\n","Epoch [87/100], Loss: 867.0711\n","Epoch [88/100], Loss: 863.1542\n","Epoch [89/100], Loss: 865.8785\n","Epoch [90/100], Loss: 864.8738\n","Epoch [91/100], Loss: 863.9342\n","Epoch [92/100], Loss: 864.8726\n","Epoch [93/100], Loss: 864.9634\n","Epoch [94/100], Loss: 864.8164\n","Epoch [95/100], Loss: 862.8558\n","Epoch [96/100], Loss: 864.1463\n","Epoch [97/100], Loss: 861.8981\n","Epoch [98/100], Loss: 865.2914\n","Epoch [99/100], Loss: 863.4356\n","Epoch [100/100], Loss: 860.2182\n","Processed humanGBM successfully.\n","Epoch [1/100], Loss: 6051.6870\n","Epoch [2/100], Loss: 5276.8179\n","Epoch [3/100], Loss: 4820.9609\n","Epoch [4/100], Loss: 4411.4834\n","Epoch [5/100], Loss: 4028.0928\n","Epoch [6/100], Loss: 3715.7979\n","Epoch [7/100], Loss: 3457.8655\n","Epoch [8/100], Loss: 3229.1272\n","Epoch [9/100], Loss: 3065.8860\n","Epoch [10/100], Loss: 2879.3528\n","Epoch [11/100], Loss: 2727.9958\n","Epoch [12/100], Loss: 2558.3257\n","Epoch [13/100], Loss: 2427.3071\n","Epoch [14/100], Loss: 2299.9951\n","Epoch [15/100], Loss: 2172.6423\n","Epoch [16/100], Loss: 2057.1382\n","Epoch [17/100], Loss: 1949.3699\n","Epoch [18/100], Loss: 1867.2168\n","Epoch [19/100], Loss: 1775.3556\n","Epoch [20/100], Loss: 1701.5006\n","Epoch [21/100], Loss: 1632.8478\n","Epoch [22/100], Loss: 1568.3599\n","Epoch [23/100], Loss: 1523.0555\n","Epoch [24/100], Loss: 1468.2024\n","Epoch [25/100], Loss: 1425.4720\n","Epoch [26/100], Loss: 1381.3147\n","Epoch [27/100], Loss: 1341.0559\n","Epoch [28/100], Loss: 1309.7965\n","Epoch [29/100], Loss: 1283.4154\n","Epoch [30/100], Loss: 1252.9191\n","Epoch [31/100], Loss: 1230.6755\n","Epoch [32/100], Loss: 1210.4592\n","Epoch [33/100], Loss: 1190.2911\n","Epoch [34/100], Loss: 1174.0002\n","Epoch [35/100], Loss: 1155.5807\n","Epoch [36/100], Loss: 1140.6177\n","Epoch [37/100], Loss: 1129.7825\n","Epoch [38/100], Loss: 1115.7822\n","Epoch [39/100], Loss: 1104.2369\n","Epoch [40/100], Loss: 1097.4255\n","Epoch [41/100], Loss: 1089.3735\n","Epoch [42/100], Loss: 1079.8849\n","Epoch [43/100], Loss: 1069.2577\n","Epoch [44/100], Loss: 1065.0369\n","Epoch [45/100], Loss: 1057.7933\n","Epoch [46/100], Loss: 1051.2283\n","Epoch [47/100], Loss: 1043.7374\n","Epoch [48/100], Loss: 1038.3668\n","Epoch [49/100], Loss: 1035.1216\n","Epoch [50/100], Loss: 1028.7549\n","Epoch [51/100], Loss: 1028.2760\n","Epoch [52/100], Loss: 1020.4205\n","Epoch [53/100], Loss: 1020.2300\n","Epoch [54/100], Loss: 1011.4459\n","Epoch [55/100], Loss: 1010.6254\n","Epoch [56/100], Loss: 1011.7058\n","Epoch [57/100], Loss: 1007.5851\n","Epoch [58/100], Loss: 1007.5613\n","Epoch [59/100], Loss: 1002.3026\n","Epoch [60/100], Loss: 1000.9547\n","Epoch [61/100], Loss: 999.2578\n","Epoch [62/100], Loss: 1002.3652\n","Epoch [63/100], Loss: 994.8005\n","Epoch [64/100], Loss: 993.2505\n","Epoch [65/100], Loss: 990.0720\n","Epoch [66/100], Loss: 989.7397\n","Epoch [67/100], Loss: 989.7811\n","Epoch [68/100], Loss: 988.8040\n","Epoch [69/100], Loss: 987.2057\n","Epoch [70/100], Loss: 980.3477\n","Epoch [71/100], Loss: 985.4814\n","Epoch [72/100], Loss: 979.9197\n","Epoch [73/100], Loss: 979.4820\n","Epoch [74/100], Loss: 981.3608\n","Epoch [75/100], Loss: 975.6808\n","Epoch [76/100], Loss: 975.8473\n","Epoch [77/100], Loss: 979.1878\n","Epoch [78/100], Loss: 976.3947\n","Epoch [79/100], Loss: 977.4578\n","Epoch [80/100], Loss: 972.1766\n","Epoch [81/100], Loss: 973.0995\n","Epoch [82/100], Loss: 972.5564\n","Epoch [83/100], Loss: 971.0256\n","Epoch [84/100], Loss: 970.2239\n","Epoch [85/100], Loss: 972.4470\n","Epoch [86/100], Loss: 971.7917\n","Epoch [87/100], Loss: 969.1092\n","Epoch [88/100], Loss: 967.3282\n","Epoch [89/100], Loss: 967.8112\n","Epoch [90/100], Loss: 966.9319\n","Epoch [91/100], Loss: 965.8304\n","Epoch [92/100], Loss: 968.3910\n","Epoch [93/100], Loss: 967.4865\n","Epoch [94/100], Loss: 964.4474\n","Epoch [95/100], Loss: 964.2731\n","Epoch [96/100], Loss: 964.8787\n","Epoch [97/100], Loss: 962.2934\n","Epoch [98/100], Loss: 961.4881\n","Epoch [99/100], Loss: 960.6821\n","Epoch [100/100], Loss: 963.3987\n","Processed humanskin successfully.\n","Epoch [1/100], Loss: 6892.4790\n","Epoch [2/100], Loss: 5837.0361\n","Epoch [3/100], Loss: 5173.9185\n","Epoch [4/100], Loss: 4563.3794\n","Epoch [5/100], Loss: 4051.4778\n","Epoch [6/100], Loss: 3630.3733\n","Epoch [7/100], Loss: 3286.2891\n","Epoch [8/100], Loss: 3009.7964\n","Epoch [9/100], Loss: 2789.2747\n","Epoch [10/100], Loss: 2596.3208\n","Epoch [11/100], Loss: 2447.9519\n","Epoch [12/100], Loss: 2292.4141\n","Epoch [13/100], Loss: 2165.2532\n","Epoch [14/100], Loss: 2030.9032\n","Epoch [15/100], Loss: 1909.3297\n","Epoch [16/100], Loss: 1802.0802\n","Epoch [17/100], Loss: 1705.9362\n","Epoch [18/100], Loss: 1610.2925\n","Epoch [19/100], Loss: 1510.9186\n","Epoch [20/100], Loss: 1439.6163\n","Epoch [21/100], Loss: 1358.3612\n","Epoch [22/100], Loss: 1291.7184\n","Epoch [23/100], Loss: 1236.9561\n","Epoch [24/100], Loss: 1181.8551\n","Epoch [25/100], Loss: 1132.5887\n","Epoch [26/100], Loss: 1091.7262\n","Epoch [27/100], Loss: 1056.2517\n","Epoch [28/100], Loss: 1026.5249\n","Epoch [29/100], Loss: 993.5991\n","Epoch [30/100], Loss: 965.4594\n","Epoch [31/100], Loss: 945.1555\n","Epoch [32/100], Loss: 920.2195\n","Epoch [33/100], Loss: 902.5851\n","Epoch [34/100], Loss: 884.0251\n","Epoch [35/100], Loss: 867.4507\n","Epoch [36/100], Loss: 852.8678\n","Epoch [37/100], Loss: 836.1876\n","Epoch [38/100], Loss: 825.2159\n","Epoch [39/100], Loss: 814.6907\n","Epoch [40/100], Loss: 805.1194\n","Epoch [41/100], Loss: 790.5067\n","Epoch [42/100], Loss: 783.8624\n","Epoch [43/100], Loss: 775.9393\n","Epoch [44/100], Loss: 769.0093\n","Epoch [45/100], Loss: 761.5739\n","Epoch [46/100], Loss: 751.7665\n","Epoch [47/100], Loss: 748.7883\n","Epoch [48/100], Loss: 745.1080\n","Epoch [49/100], Loss: 738.3765\n","Epoch [50/100], Loss: 733.9744\n","Epoch [51/100], Loss: 729.4152\n","Epoch [52/100], Loss: 728.7399\n","Epoch [53/100], Loss: 723.4368\n","Epoch [54/100], Loss: 723.1068\n","Epoch [55/100], Loss: 717.4446\n","Epoch [56/100], Loss: 714.5055\n","Epoch [57/100], Loss: 712.5425\n","Epoch [58/100], Loss: 709.6306\n","Epoch [59/100], Loss: 705.3517\n","Epoch [60/100], Loss: 704.2332\n","Epoch [61/100], Loss: 700.3909\n","Epoch [62/100], Loss: 698.8679\n","Epoch [63/100], Loss: 694.2392\n","Epoch [64/100], Loss: 694.4078\n","Epoch [65/100], Loss: 694.0760\n","Epoch [66/100], Loss: 691.9271\n","Epoch [67/100], Loss: 689.8025\n","Epoch [68/100], Loss: 687.2026\n","Epoch [69/100], Loss: 685.7651\n","Epoch [70/100], Loss: 683.8981\n","Epoch [71/100], Loss: 683.3194\n","Epoch [72/100], Loss: 685.1663\n","Epoch [73/100], Loss: 682.2344\n","Epoch [74/100], Loss: 678.7170\n","Epoch [75/100], Loss: 681.2237\n","Epoch [76/100], Loss: 679.0912\n","Epoch [77/100], Loss: 676.1947\n","Epoch [78/100], Loss: 676.8815\n","Epoch [79/100], Loss: 672.5244\n","Epoch [80/100], Loss: 673.4350\n","Epoch [81/100], Loss: 674.3227\n","Epoch [82/100], Loss: 672.1697\n","Epoch [83/100], Loss: 674.1794\n","Epoch [84/100], Loss: 668.5487\n","Epoch [85/100], Loss: 670.1873\n","Epoch [86/100], Loss: 665.0491\n","Epoch [87/100], Loss: 666.3557\n","Epoch [88/100], Loss: 666.8908\n","Epoch [89/100], Loss: 665.4774\n","Epoch [90/100], Loss: 663.1793\n","Epoch [91/100], Loss: 663.3181\n","Epoch [92/100], Loss: 665.3823\n","Epoch [93/100], Loss: 665.1608\n","Epoch [94/100], Loss: 660.3480\n","Epoch [95/100], Loss: 663.1788\n","Epoch [96/100], Loss: 663.0632\n","Epoch [97/100], Loss: 662.0653\n","Epoch [98/100], Loss: 659.0765\n","Epoch [99/100], Loss: 661.4889\n","Epoch [100/100], Loss: 658.4969\n","Processed humanthymus successfully.\n","Epoch [1/100], Loss: 6085.6934\n","Epoch [2/100], Loss: 5307.3374\n","Epoch [3/100], Loss: 4785.2798\n","Epoch [4/100], Loss: 4256.6123\n","Epoch [5/100], Loss: 3830.0544\n","Epoch [6/100], Loss: 3478.0117\n","Epoch [7/100], Loss: 3183.3474\n","Epoch [8/100], Loss: 2910.3364\n","Epoch [9/100], Loss: 2703.0332\n","Epoch [10/100], Loss: 2529.0386\n","Epoch [11/100], Loss: 2351.6741\n","Epoch [12/100], Loss: 2214.1370\n","Epoch [13/100], Loss: 2064.1492\n","Epoch [14/100], Loss: 1948.8936\n","Epoch [15/100], Loss: 1836.2440\n","Epoch [16/100], Loss: 1718.7856\n","Epoch [17/100], Loss: 1622.4956\n","Epoch [18/100], Loss: 1536.2133\n","Epoch [19/100], Loss: 1456.0023\n","Epoch [20/100], Loss: 1378.1841\n","Epoch [21/100], Loss: 1304.0183\n","Epoch [22/100], Loss: 1248.8524\n","Epoch [23/100], Loss: 1193.8397\n","Epoch [24/100], Loss: 1148.6411\n","Epoch [25/100], Loss: 1104.4243\n","Epoch [26/100], Loss: 1068.5216\n","Epoch [27/100], Loss: 1035.3126\n","Epoch [28/100], Loss: 1005.9677\n","Epoch [29/100], Loss: 981.7608\n","Epoch [30/100], Loss: 956.5703\n","Epoch [31/100], Loss: 933.4136\n","Epoch [32/100], Loss: 915.2808\n","Epoch [33/100], Loss: 894.3035\n","Epoch [34/100], Loss: 880.8652\n","Epoch [35/100], Loss: 866.2783\n","Epoch [36/100], Loss: 851.7310\n","Epoch [37/100], Loss: 840.0695\n","Epoch [38/100], Loss: 828.0123\n","Epoch [39/100], Loss: 819.4063\n","Epoch [40/100], Loss: 808.0081\n","Epoch [41/100], Loss: 798.8517\n","Epoch [42/100], Loss: 793.8344\n","Epoch [43/100], Loss: 784.2310\n","Epoch [44/100], Loss: 779.1731\n","Epoch [45/100], Loss: 773.0162\n","Epoch [46/100], Loss: 765.9875\n","Epoch [47/100], Loss: 762.8124\n","Epoch [48/100], Loss: 757.9937\n","Epoch [49/100], Loss: 753.9734\n","Epoch [50/100], Loss: 747.5460\n","Epoch [51/100], Loss: 746.1975\n","Epoch [52/100], Loss: 742.3895\n","Epoch [53/100], Loss: 739.4555\n","Epoch [54/100], Loss: 735.5234\n","Epoch [55/100], Loss: 731.2333\n","Epoch [56/100], Loss: 732.6440\n","Epoch [57/100], Loss: 725.3024\n","Epoch [58/100], Loss: 725.3600\n","Epoch [59/100], Loss: 725.3682\n","Epoch [60/100], Loss: 721.9959\n","Epoch [61/100], Loss: 717.9748\n","Epoch [62/100], Loss: 716.6895\n","Epoch [63/100], Loss: 717.8672\n","Epoch [64/100], Loss: 715.7855\n","Epoch [65/100], Loss: 714.4495\n","Epoch [66/100], Loss: 713.7794\n","Epoch [67/100], Loss: 712.5410\n","Epoch [68/100], Loss: 707.8515\n","Epoch [69/100], Loss: 708.1992\n","Epoch [70/100], Loss: 707.2930\n","Epoch [71/100], Loss: 708.6919\n","Epoch [72/100], Loss: 704.8128\n","Epoch [73/100], Loss: 706.4473\n","Epoch [74/100], Loss: 704.2834\n","Epoch [75/100], Loss: 703.5297\n","Epoch [76/100], Loss: 702.3472\n","Epoch [77/100], Loss: 701.3090\n","Epoch [78/100], Loss: 701.3176\n","Epoch [79/100], Loss: 700.5062\n","Epoch [80/100], Loss: 700.2552\n","Epoch [81/100], Loss: 698.7992\n","Epoch [82/100], Loss: 698.2162\n","Epoch [83/100], Loss: 698.4293\n","Epoch [84/100], Loss: 694.0438\n","Epoch [85/100], Loss: 696.3232\n","Epoch [86/100], Loss: 695.1111\n","Epoch [87/100], Loss: 693.7551\n","Epoch [88/100], Loss: 695.0018\n","Epoch [89/100], Loss: 693.2997\n","Epoch [90/100], Loss: 692.1736\n","Epoch [91/100], Loss: 694.9247\n","Epoch [92/100], Loss: 692.2383\n","Epoch [93/100], Loss: 691.3853\n","Epoch [94/100], Loss: 690.0855\n","Epoch [95/100], Loss: 691.4009\n","Epoch [96/100], Loss: 691.2219\n","Epoch [97/100], Loss: 691.7869\n","Epoch [98/100], Loss: 689.8751\n","Epoch [99/100], Loss: 690.5103\n","Epoch [100/100], Loss: 690.9128\n","Processed humanspleen successfully.\n","Epoch [1/100], Loss: 6606.1099\n","Epoch [2/100], Loss: 5587.8105\n","Epoch [3/100], Loss: 4941.2471\n","Epoch [4/100], Loss: 4375.2261\n","Epoch [5/100], Loss: 3889.4910\n","Epoch [6/100], Loss: 3509.6909\n","Epoch [7/100], Loss: 3185.5713\n","Epoch [8/100], Loss: 2912.5376\n","Epoch [9/100], Loss: 2685.7932\n","Epoch [10/100], Loss: 2494.6797\n","Epoch [11/100], Loss: 2331.4307\n","Epoch [12/100], Loss: 2169.2734\n","Epoch [13/100], Loss: 2051.0381\n","Epoch [14/100], Loss: 1923.2183\n","Epoch [15/100], Loss: 1777.4751\n","Epoch [16/100], Loss: 1674.7150\n","Epoch [17/100], Loss: 1573.1470\n","Epoch [18/100], Loss: 1483.2646\n","Epoch [19/100], Loss: 1391.5311\n","Epoch [20/100], Loss: 1310.1830\n","Epoch [21/100], Loss: 1241.0020\n","Epoch [22/100], Loss: 1173.3424\n","Epoch [23/100], Loss: 1112.3463\n","Epoch [24/100], Loss: 1064.5706\n","Epoch [25/100], Loss: 1013.0229\n","Epoch [26/100], Loss: 979.7897\n","Epoch [27/100], Loss: 943.3085\n","Epoch [28/100], Loss: 912.0723\n","Epoch [29/100], Loss: 882.2796\n","Epoch [30/100], Loss: 857.8226\n","Epoch [31/100], Loss: 831.0871\n","Epoch [32/100], Loss: 812.3922\n","Epoch [33/100], Loss: 791.8699\n","Epoch [34/100], Loss: 775.1595\n","Epoch [35/100], Loss: 758.6722\n","Epoch [36/100], Loss: 745.3861\n","Epoch [37/100], Loss: 731.5532\n","Epoch [38/100], Loss: 717.2240\n","Epoch [39/100], Loss: 705.5560\n","Epoch [40/100], Loss: 694.7024\n","Epoch [41/100], Loss: 686.4946\n","Epoch [42/100], Loss: 677.7082\n","Epoch [43/100], Loss: 667.6464\n","Epoch [44/100], Loss: 662.8945\n","Epoch [45/100], Loss: 655.9960\n","Epoch [46/100], Loss: 649.5553\n","Epoch [47/100], Loss: 642.5512\n","Epoch [48/100], Loss: 637.0643\n","Epoch [49/100], Loss: 634.1239\n","Epoch [50/100], Loss: 628.3015\n","Epoch [51/100], Loss: 627.1362\n","Epoch [52/100], Loss: 620.0153\n","Epoch [53/100], Loss: 614.9326\n","Epoch [54/100], Loss: 613.4389\n","Epoch [55/100], Loss: 608.7911\n","Epoch [56/100], Loss: 607.7864\n","Epoch [57/100], Loss: 603.5052\n","Epoch [58/100], Loss: 601.8885\n","Epoch [59/100], Loss: 598.4334\n","Epoch [60/100], Loss: 597.1022\n","Epoch [61/100], Loss: 593.3186\n","Epoch [62/100], Loss: 589.6616\n","Epoch [63/100], Loss: 590.1037\n","Epoch [64/100], Loss: 590.2492\n","Epoch [65/100], Loss: 586.1346\n","Epoch [66/100], Loss: 583.5460\n","Epoch [67/100], Loss: 583.7208\n","Epoch [68/100], Loss: 581.2524\n","Epoch [69/100], Loss: 579.3992\n","Epoch [70/100], Loss: 575.9798\n","Epoch [71/100], Loss: 577.6838\n","Epoch [72/100], Loss: 575.1840\n","Epoch [73/100], Loss: 575.4748\n","Epoch [74/100], Loss: 571.8711\n","Epoch [75/100], Loss: 572.9436\n","Epoch [76/100], Loss: 570.7155\n","Epoch [77/100], Loss: 569.9402\n","Epoch [78/100], Loss: 569.1815\n","Epoch [79/100], Loss: 567.0254\n","Epoch [80/100], Loss: 565.9754\n","Epoch [81/100], Loss: 566.9752\n","Epoch [82/100], Loss: 564.3113\n","Epoch [83/100], Loss: 563.0840\n","Epoch [84/100], Loss: 564.3761\n","Epoch [85/100], Loss: 562.2885\n","Epoch [86/100], Loss: 563.7794\n","Epoch [87/100], Loss: 559.8069\n","Epoch [88/100], Loss: 560.5348\n","Epoch [89/100], Loss: 558.6569\n","Epoch [90/100], Loss: 558.9962\n","Epoch [91/100], Loss: 555.6654\n","Epoch [92/100], Loss: 557.9071\n","Epoch [93/100], Loss: 556.7993\n","Epoch [94/100], Loss: 554.3198\n","Epoch [95/100], Loss: 553.2923\n","Epoch [96/100], Loss: 554.6974\n","Epoch [97/100], Loss: 553.6304\n","Epoch [98/100], Loss: 553.7701\n","Epoch [99/100], Loss: 550.6675\n","Epoch [100/100], Loss: 551.2644\n","Processed humantonsil successfully.\n","Epoch [1/100], Loss: 6021.1191\n","Epoch [2/100], Loss: 5211.3867\n","Epoch [3/100], Loss: 4702.2070\n","Epoch [4/100], Loss: 4246.4863\n","Epoch [5/100], Loss: 3816.4849\n","Epoch [6/100], Loss: 3464.3599\n","Epoch [7/100], Loss: 3163.3220\n","Epoch [8/100], Loss: 2917.2173\n","Epoch [9/100], Loss: 2683.5671\n","Epoch [10/100], Loss: 2494.8992\n","Epoch [11/100], Loss: 2324.6218\n","Epoch [12/100], Loss: 2173.0342\n","Epoch [13/100], Loss: 2030.8802\n","Epoch [14/100], Loss: 1903.0452\n","Epoch [15/100], Loss: 1780.3268\n","Epoch [16/100], Loss: 1685.7283\n","Epoch [17/100], Loss: 1590.2921\n","Epoch [18/100], Loss: 1501.6985\n","Epoch [19/100], Loss: 1426.8309\n","Epoch [20/100], Loss: 1347.3429\n","Epoch [21/100], Loss: 1276.4623\n","Epoch [22/100], Loss: 1216.6039\n","Epoch [23/100], Loss: 1164.0383\n","Epoch [24/100], Loss: 1119.0013\n","Epoch [25/100], Loss: 1073.1227\n","Epoch [26/100], Loss: 1036.9999\n","Epoch [27/100], Loss: 1007.1815\n","Epoch [28/100], Loss: 974.5690\n","Epoch [29/100], Loss: 946.7979\n","Epoch [30/100], Loss: 922.5791\n","Epoch [31/100], Loss: 900.7347\n","Epoch [32/100], Loss: 879.0584\n","Epoch [33/100], Loss: 864.0275\n","Epoch [34/100], Loss: 848.5927\n","Epoch [35/100], Loss: 829.8116\n","Epoch [36/100], Loss: 815.0818\n","Epoch [37/100], Loss: 802.0040\n","Epoch [38/100], Loss: 792.1859\n","Epoch [39/100], Loss: 779.8842\n","Epoch [40/100], Loss: 773.2579\n","Epoch [41/100], Loss: 765.4333\n","Epoch [42/100], Loss: 756.7661\n","Epoch [43/100], Loss: 749.7087\n","Epoch [44/100], Loss: 743.4424\n","Epoch [45/100], Loss: 736.6896\n","Epoch [46/100], Loss: 733.2571\n","Epoch [47/100], Loss: 727.9352\n","Epoch [48/100], Loss: 722.8992\n","Epoch [49/100], Loss: 715.9162\n","Epoch [50/100], Loss: 712.4234\n","Epoch [51/100], Loss: 711.0127\n","Epoch [52/100], Loss: 707.6519\n","Epoch [53/100], Loss: 704.4333\n","Epoch [54/100], Loss: 698.2091\n","Epoch [55/100], Loss: 696.7898\n","Epoch [56/100], Loss: 695.4047\n","Epoch [57/100], Loss: 692.1070\n","Epoch [58/100], Loss: 688.6776\n","Epoch [59/100], Loss: 685.9964\n","Epoch [60/100], Loss: 682.4781\n","Epoch [61/100], Loss: 686.7999\n","Epoch [62/100], Loss: 682.2922\n","Epoch [63/100], Loss: 682.2964\n","Epoch [64/100], Loss: 679.6364\n","Epoch [65/100], Loss: 677.8024\n","Epoch [66/100], Loss: 677.4255\n","Epoch [67/100], Loss: 676.4781\n","Epoch [68/100], Loss: 675.2757\n","Epoch [69/100], Loss: 672.4764\n","Epoch [70/100], Loss: 671.8783\n","Epoch [71/100], Loss: 669.6419\n","Epoch [72/100], Loss: 669.1708\n","Epoch [73/100], Loss: 667.9694\n","Epoch [74/100], Loss: 665.4969\n","Epoch [75/100], Loss: 667.2299\n","Epoch [76/100], Loss: 665.4222\n","Epoch [77/100], Loss: 664.0626\n","Epoch [78/100], Loss: 662.5118\n","Epoch [79/100], Loss: 664.1926\n","Epoch [80/100], Loss: 661.3146\n","Epoch [81/100], Loss: 660.5883\n","Epoch [82/100], Loss: 659.5648\n","Epoch [83/100], Loss: 658.2638\n","Epoch [84/100], Loss: 659.0305\n","Epoch [85/100], Loss: 659.3265\n","Epoch [86/100], Loss: 657.5641\n","Epoch [87/100], Loss: 658.1483\n","Epoch [88/100], Loss: 656.9445\n","Epoch [89/100], Loss: 656.2304\n","Epoch [90/100], Loss: 657.6708\n","Epoch [91/100], Loss: 656.9460\n","Epoch [92/100], Loss: 653.3468\n","Epoch [93/100], Loss: 653.8924\n","Epoch [94/100], Loss: 651.2393\n","Epoch [95/100], Loss: 653.9921\n","Epoch [96/100], Loss: 654.5810\n","Epoch [97/100], Loss: 653.0865\n","Epoch [98/100], Loss: 652.8447\n","Epoch [99/100], Loss: 651.6017\n","Epoch [100/100], Loss: 653.3578\n","Processed mousekidney successfully.\n","Epoch [1/100], Loss: 5739.2861\n","Epoch [2/100], Loss: 5031.3481\n","Epoch [3/100], Loss: 4646.3545\n","Epoch [4/100], Loss: 4208.1606\n","Epoch [5/100], Loss: 3863.0906\n","Epoch [6/100], Loss: 3550.0432\n","Epoch [7/100], Loss: 3298.8406\n","Epoch [8/100], Loss: 3093.0437\n","Epoch [9/100], Loss: 2886.4631\n","Epoch [10/100], Loss: 2687.7539\n","Epoch [11/100], Loss: 2536.1628\n","Epoch [12/100], Loss: 2400.1702\n","Epoch [13/100], Loss: 2266.2769\n","Epoch [14/100], Loss: 2114.5388\n","Epoch [15/100], Loss: 2005.7306\n","Epoch [16/100], Loss: 1895.3999\n","Epoch [17/100], Loss: 1784.4874\n","Epoch [18/100], Loss: 1712.4454\n","Epoch [19/100], Loss: 1616.2919\n","Epoch [20/100], Loss: 1534.4730\n","Epoch [21/100], Loss: 1461.0616\n","Epoch [22/100], Loss: 1392.8917\n","Epoch [23/100], Loss: 1332.6615\n","Epoch [24/100], Loss: 1279.9084\n","Epoch [25/100], Loss: 1244.7494\n","Epoch [26/100], Loss: 1190.3282\n","Epoch [27/100], Loss: 1151.5081\n","Epoch [28/100], Loss: 1114.2699\n","Epoch [29/100], Loss: 1087.2139\n","Epoch [30/100], Loss: 1052.8773\n","Epoch [31/100], Loss: 1031.6034\n","Epoch [32/100], Loss: 1007.7602\n","Epoch [33/100], Loss: 983.8714\n","Epoch [34/100], Loss: 965.0187\n","Epoch [35/100], Loss: 946.6876\n","Epoch [36/100], Loss: 931.7833\n","Epoch [37/100], Loss: 916.8949\n","Epoch [38/100], Loss: 898.7532\n","Epoch [39/100], Loss: 891.7709\n","Epoch [40/100], Loss: 876.7747\n","Epoch [41/100], Loss: 872.7687\n","Epoch [42/100], Loss: 860.8463\n","Epoch [43/100], Loss: 849.9160\n","Epoch [44/100], Loss: 842.7804\n","Epoch [45/100], Loss: 829.9521\n","Epoch [46/100], Loss: 831.4714\n","Epoch [47/100], Loss: 826.5859\n","Epoch [48/100], Loss: 816.8411\n","Epoch [49/100], Loss: 809.0549\n","Epoch [50/100], Loss: 806.0870\n","Epoch [51/100], Loss: 802.9824\n","Epoch [52/100], Loss: 801.7496\n","Epoch [53/100], Loss: 792.0380\n","Epoch [54/100], Loss: 793.4482\n","Epoch [55/100], Loss: 784.3298\n","Epoch [56/100], Loss: 782.3333\n","Epoch [57/100], Loss: 775.0746\n","Epoch [58/100], Loss: 780.3310\n","Epoch [59/100], Loss: 774.1932\n","Epoch [60/100], Loss: 772.7291\n","Epoch [61/100], Loss: 771.5850\n","Epoch [62/100], Loss: 769.3340\n","Epoch [63/100], Loss: 765.0232\n","Epoch [64/100], Loss: 764.7357\n","Epoch [65/100], Loss: 758.0562\n","Epoch [66/100], Loss: 759.5095\n","Epoch [67/100], Loss: 764.0222\n","Epoch [68/100], Loss: 756.0483\n","Epoch [69/100], Loss: 754.2430\n","Epoch [70/100], Loss: 755.5685\n","Epoch [71/100], Loss: 755.4540\n","Epoch [72/100], Loss: 748.6798\n","Epoch [73/100], Loss: 752.9851\n","Epoch [74/100], Loss: 752.1418\n","Epoch [75/100], Loss: 746.3267\n","Epoch [76/100], Loss: 747.7596\n","Epoch [77/100], Loss: 745.1567\n","Epoch [78/100], Loss: 746.5717\n","Epoch [79/100], Loss: 745.9527\n","Epoch [80/100], Loss: 743.6099\n","Epoch [81/100], Loss: 748.0106\n","Epoch [82/100], Loss: 745.3653\n","Epoch [83/100], Loss: 746.4179\n","Epoch [84/100], Loss: 740.4554\n","Epoch [85/100], Loss: 743.0434\n","Epoch [86/100], Loss: 741.5797\n","Epoch [87/100], Loss: 739.1255\n","Epoch [88/100], Loss: 740.8908\n","Epoch [89/100], Loss: 742.0256\n","Epoch [90/100], Loss: 738.6111\n","Epoch [91/100], Loss: 738.3085\n","Epoch [92/100], Loss: 738.1533\n","Epoch [93/100], Loss: 737.4450\n","Epoch [94/100], Loss: 736.5168\n","Epoch [95/100], Loss: 737.0668\n","Epoch [96/100], Loss: 736.2037\n","Epoch [97/100], Loss: 736.7683\n","Epoch [98/100], Loss: 734.0674\n","Epoch [99/100], Loss: 739.6259\n","Epoch [100/100], Loss: 735.0748\n","Processed mouseintestine successfully.\n","Epoch [1/100], Loss: 6142.5039\n","Epoch [2/100], Loss: 5360.6304\n","Epoch [3/100], Loss: 4855.1035\n","Epoch [4/100], Loss: 4371.6602\n","Epoch [5/100], Loss: 3922.0706\n","Epoch [6/100], Loss: 3558.8613\n","Epoch [7/100], Loss: 3249.1873\n","Epoch [8/100], Loss: 2998.5125\n","Epoch [9/100], Loss: 2776.7378\n","Epoch [10/100], Loss: 2575.3425\n","Epoch [11/100], Loss: 2401.6572\n","Epoch [12/100], Loss: 2248.3696\n","Epoch [13/100], Loss: 2110.3572\n","Epoch [14/100], Loss: 1986.5975\n","Epoch [15/100], Loss: 1874.4802\n","Epoch [16/100], Loss: 1771.3750\n","Epoch [17/100], Loss: 1669.5631\n","Epoch [18/100], Loss: 1577.3531\n","Epoch [19/100], Loss: 1500.6554\n","Epoch [20/100], Loss: 1424.2552\n","Epoch [21/100], Loss: 1353.6820\n","Epoch [22/100], Loss: 1289.4858\n","Epoch [23/100], Loss: 1236.8221\n","Epoch [24/100], Loss: 1187.6976\n","Epoch [25/100], Loss: 1148.3069\n","Epoch [26/100], Loss: 1104.6813\n","Epoch [27/100], Loss: 1071.4604\n","Epoch [28/100], Loss: 1040.2192\n","Epoch [29/100], Loss: 1010.4129\n","Epoch [30/100], Loss: 988.1445\n","Epoch [31/100], Loss: 966.5775\n","Epoch [32/100], Loss: 945.4315\n","Epoch [33/100], Loss: 926.4214\n","Epoch [34/100], Loss: 907.8538\n","Epoch [35/100], Loss: 893.9317\n","Epoch [36/100], Loss: 882.7985\n","Epoch [37/100], Loss: 867.8187\n","Epoch [38/100], Loss: 858.4768\n","Epoch [39/100], Loss: 849.2830\n","Epoch [40/100], Loss: 842.8444\n","Epoch [41/100], Loss: 833.6057\n","Epoch [42/100], Loss: 824.4481\n","Epoch [43/100], Loss: 813.3237\n","Epoch [44/100], Loss: 810.1421\n","Epoch [45/100], Loss: 804.6426\n","Epoch [46/100], Loss: 800.2516\n","Epoch [47/100], Loss: 789.9879\n","Epoch [48/100], Loss: 788.8046\n","Epoch [49/100], Loss: 785.3083\n","Epoch [50/100], Loss: 779.6003\n","Epoch [51/100], Loss: 775.8981\n","Epoch [52/100], Loss: 773.4607\n","Epoch [53/100], Loss: 771.0358\n","Epoch [54/100], Loss: 767.5137\n","Epoch [55/100], Loss: 763.7344\n","Epoch [56/100], Loss: 760.7208\n","Epoch [57/100], Loss: 759.9339\n","Epoch [58/100], Loss: 756.8258\n","Epoch [59/100], Loss: 753.8306\n","Epoch [60/100], Loss: 755.0666\n","Epoch [61/100], Loss: 750.6193\n","Epoch [62/100], Loss: 750.8163\n","Epoch [63/100], Loss: 748.4199\n","Epoch [64/100], Loss: 747.0742\n","Epoch [65/100], Loss: 744.4064\n","Epoch [66/100], Loss: 744.6923\n","Epoch [67/100], Loss: 743.4440\n","Epoch [68/100], Loss: 737.2496\n","Epoch [69/100], Loss: 739.4997\n","Epoch [70/100], Loss: 738.1707\n","Epoch [71/100], Loss: 736.9911\n","Epoch [72/100], Loss: 737.7775\n","Epoch [73/100], Loss: 734.7441\n","Epoch [74/100], Loss: 734.1337\n","Epoch [75/100], Loss: 733.5046\n","Epoch [76/100], Loss: 732.1337\n","Epoch [77/100], Loss: 729.4417\n","Epoch [78/100], Loss: 733.6126\n","Epoch [79/100], Loss: 730.1113\n","Epoch [80/100], Loss: 728.0220\n","Epoch [81/100], Loss: 726.6202\n","Epoch [82/100], Loss: 726.9969\n","Epoch [83/100], Loss: 727.9042\n","Epoch [84/100], Loss: 728.4400\n","Epoch [85/100], Loss: 726.4521\n","Epoch [86/100], Loss: 725.2184\n","Epoch [87/100], Loss: 724.4866\n","Epoch [88/100], Loss: 724.6536\n","Epoch [89/100], Loss: 725.9393\n","Epoch [90/100], Loss: 723.8542\n","Epoch [91/100], Loss: 721.4917\n","Epoch [92/100], Loss: 723.3690\n","Epoch [93/100], Loss: 721.6185\n","Epoch [94/100], Loss: 722.7557\n","Epoch [95/100], Loss: 723.6494\n","Epoch [96/100], Loss: 722.5275\n","Epoch [97/100], Loss: 720.3777\n","Epoch [98/100], Loss: 718.6736\n","Epoch [99/100], Loss: 719.9652\n","Epoch [100/100], Loss: 721.2793\n","Processed mousecolon successfully.\n","Epoch [1/100], Loss: 6123.0273\n","Epoch [2/100], Loss: 5319.9731\n","Epoch [3/100], Loss: 4908.3799\n","Epoch [4/100], Loss: 4493.0806\n","Epoch [5/100], Loss: 4110.5195\n","Epoch [6/100], Loss: 3791.5781\n","Epoch [7/100], Loss: 3554.9565\n","Epoch [8/100], Loss: 3321.3472\n","Epoch [9/100], Loss: 3123.4893\n","Epoch [10/100], Loss: 2923.4722\n","Epoch [11/100], Loss: 2756.5767\n","Epoch [12/100], Loss: 2610.2500\n","Epoch [13/100], Loss: 2479.2446\n","Epoch [14/100], Loss: 2353.9546\n","Epoch [15/100], Loss: 2229.7273\n","Epoch [16/100], Loss: 2124.7039\n","Epoch [17/100], Loss: 2022.2036\n","Epoch [18/100], Loss: 1926.8424\n","Epoch [19/100], Loss: 1841.6416\n","Epoch [20/100], Loss: 1765.8422\n","Epoch [21/100], Loss: 1702.0406\n","Epoch [22/100], Loss: 1632.2880\n","Epoch [23/100], Loss: 1576.0601\n","Epoch [24/100], Loss: 1523.9175\n","Epoch [25/100], Loss: 1470.6213\n","Epoch [26/100], Loss: 1431.4076\n","Epoch [27/100], Loss: 1391.6725\n","Epoch [28/100], Loss: 1355.6749\n","Epoch [29/100], Loss: 1320.6923\n","Epoch [30/100], Loss: 1292.0570\n","Epoch [31/100], Loss: 1271.9899\n","Epoch [32/100], Loss: 1245.1493\n","Epoch [33/100], Loss: 1226.4485\n","Epoch [34/100], Loss: 1208.9146\n","Epoch [35/100], Loss: 1188.7977\n","Epoch [36/100], Loss: 1173.3070\n","Epoch [37/100], Loss: 1154.7982\n","Epoch [38/100], Loss: 1140.3040\n","Epoch [39/100], Loss: 1130.0979\n","Epoch [40/100], Loss: 1118.4320\n","Epoch [41/100], Loss: 1107.8962\n","Epoch [42/100], Loss: 1098.3489\n","Epoch [43/100], Loss: 1091.0972\n","Epoch [44/100], Loss: 1082.5691\n","Epoch [45/100], Loss: 1077.6069\n","Epoch [46/100], Loss: 1071.5797\n","Epoch [47/100], Loss: 1063.6488\n","Epoch [48/100], Loss: 1058.1820\n","Epoch [49/100], Loss: 1054.3025\n","Epoch [50/100], Loss: 1043.3862\n","Epoch [51/100], Loss: 1043.2909\n","Epoch [52/100], Loss: 1040.4464\n","Epoch [53/100], Loss: 1033.4211\n","Epoch [54/100], Loss: 1032.6423\n","Epoch [55/100], Loss: 1026.4647\n","Epoch [56/100], Loss: 1021.5681\n","Epoch [57/100], Loss: 1022.8312\n","Epoch [58/100], Loss: 1017.3156\n","Epoch [59/100], Loss: 1015.3115\n","Epoch [60/100], Loss: 1012.7762\n","Epoch [61/100], Loss: 1014.2673\n","Epoch [62/100], Loss: 1007.0357\n","Epoch [63/100], Loss: 1005.7722\n","Epoch [64/100], Loss: 1004.3752\n","Epoch [65/100], Loss: 1003.3364\n","Epoch [66/100], Loss: 1002.5698\n","Epoch [67/100], Loss: 996.6178\n","Epoch [68/100], Loss: 995.6074\n","Epoch [69/100], Loss: 995.3936\n","Epoch [70/100], Loss: 993.0057\n","Epoch [71/100], Loss: 996.6398\n","Epoch [72/100], Loss: 994.6592\n","Epoch [73/100], Loss: 990.0167\n","Epoch [74/100], Loss: 992.0526\n","Epoch [75/100], Loss: 988.7224\n","Epoch [76/100], Loss: 985.4854\n","Epoch [77/100], Loss: 986.0756\n","Epoch [78/100], Loss: 984.3495\n","Epoch [79/100], Loss: 985.4891\n","Epoch [80/100], Loss: 982.5247\n","Epoch [81/100], Loss: 983.6561\n","Epoch [82/100], Loss: 981.7701\n","Epoch [83/100], Loss: 983.3170\n","Epoch [84/100], Loss: 980.4866\n","Epoch [85/100], Loss: 977.0856\n","Epoch [86/100], Loss: 977.6059\n","Epoch [87/100], Loss: 979.2224\n","Epoch [88/100], Loss: 977.2563\n","Epoch [89/100], Loss: 974.6156\n","Epoch [90/100], Loss: 978.9661\n","Epoch [91/100], Loss: 978.6937\n","Epoch [92/100], Loss: 970.8982\n","Epoch [93/100], Loss: 975.5056\n","Epoch [94/100], Loss: 972.9794\n","Epoch [95/100], Loss: 971.7684\n","Epoch [96/100], Loss: 971.0103\n","Epoch [97/100], Loss: 972.0930\n","Epoch [98/100], Loss: 968.6066\n","Epoch [99/100], Loss: 970.5660\n","Epoch [100/100], Loss: 968.9387\n","Processed mousespleen successfully.\n"]}],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")\n","\n","tissues= ['humanGBM', 'humanskin', 'humanthymus', 'humanspleen', 'humantonsil', 'mousekidney', 'mouseintestine', 'mousecolon', 'mousespleen']\n","\n","for tissue in tissues:\n","    rna_data = None\n","    protein_data = None\n","\n","    for filename in os.listdir(data_dir):\n","        file_path = os.path.join(data_dir, filename)\n","        if tissue in filename and filename.endswith(\"RNA.tsv.gz\"):\n","            rna_data = pd.read_csv(file_path, sep=\"\\t\")\n","        elif tissue in filename and filename.endswith(\"protein.tsv.gz\"):\n","            protein_data = pd.read_csv(file_path, sep=\"\\t\")\n","\n","    rna_data.columns = rna_data.columns.astype(str)\n","    protein_data.columns = protein_data.columns.astype(str)\n","\n","    rna_data = rna_data.sort_values(by='X')\n","    protein_data = protein_data.sort_values(by='X')\n","\n","    rna_data = rna_data.reset_index(drop=True)\n","    protein_data = protein_data.reset_index(drop=True)\n","    rna_data.index = rna_data.index.astype(str)\n","    protein_data.index = protein_data.index.astype(str)\n","\n","    rna_data[['X', 'Y']] = rna_data['X'].str.split('x', expand=True)\n","    rna_data['X'] = pd.to_numeric(rna_data['X'], errors='coerce')\n","    rna_data['Y'] = pd.to_numeric(rna_data['Y'], errors='coerce')\n","    spatial = rna_data[['X', 'Y']].copy()\n","    rna_data.drop(['X', 'Y'], axis=1, inplace=True)\n","    protein_data.drop(['X'], axis=1, inplace=True)\n","\n","    rna_train, rna_test = train_test_split(rna_data, test_size=0.2, random_state=42)\n","    protein_train = protein_data.loc[rna_train.index]\n","    protein_test = protein_data.loc[rna_test.index]\n","\n","    adata_rna_train = sc.AnnData(rna_train)\n","    sc.pp.normalize_total(adata_rna_train, target_sum=1e4)\n","    sc.pp.log1p(adata_rna_train)\n","    sc.pp.highly_variable_genes(adata_rna_train, n_top_genes=4000, flavor='seurat', subset=True)\n","    counts_norm = adata_rna_train.X\n","    rna_counts_norm = torch.FloatTensor(counts_norm).to(device)\n","\n","    adata_protein_train = sc.AnnData(protein_train)\n","    sc.pp.normalize_total(adata_protein_train, target_sum=1e4)\n","    sc.pp.log1p(adata_protein_train)\n","    counts_norm = adata_protein_train.X\n","    protein_counts_norm = torch.FloatTensor(counts_norm).to(device)\n","\n","    spatial_train = torch.tensor(spatial.loc[rna_train.index].values, dtype=torch.float32).to(device)\n","    combined_data = torch.cat([rna_counts_norm, protein_counts_norm], dim=1).to(device)\n","\n","    distances = torch.cdist(spatial_train, spatial_train, p=2)\n","    number_neighbors = 15\n","    closest_neighbors = {}\n","    furthest_neighbors = {}\n","\n","    for i in range(distances.shape[0]):\n","        sorted_indices = torch.argsort(distances[i])\n","        closest_neighbors[i] = sorted_indices[1:number_neighbors+1].cpu().numpy()\n","        furthest_neighbors[i] = sorted_indices[-number_neighbors:].cpu().numpy()\n","\n","    input_dim = combined_data.shape[1]\n","    latent_dim = 32\n","    model = VAE(input_dim, latent_dim).to(device)\n","    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n","    num_epochs = 100\n","\n","    latent_means_all = [None] * combined_data.size(0)\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        reconstructed_data, mean, logvar = model(combined_data)\n","\n","        loss = vae_loss2(reconstructed_data, combined_data, mean, logvar, closest_neighbors, furthest_neighbors,lambda_kl=0.0001, lambda_nl=1)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss / len(combined_data):.4f}')\n","\n","\n","    model.eval()\n","    with torch.no_grad():\n","        combined_data = torch.cat([rna_counts_norm, torch.zeros(rna_counts_norm.shape[0], protein_counts_norm.shape[1]).to(device)], dim=1)\n","        reconstructed_data, mean, logvar = model(combined_data)\n","        reconstructed_protein_counts = reconstructed_data[:, rna_counts_norm.shape[1]:]\n","\n","        rmse = np.sqrt(mean_squared_error(protein_counts_norm.cpu().numpy(), reconstructed_protein_counts.cpu().numpy()))\n","        pcc = pd.DataFrame(protein_counts_norm.cpu().numpy()).corrwith(pd.DataFrame(reconstructed_protein_counts.cpu().numpy()), axis=1, method='pearson')\n","        avg_corr_pearson = pcc.mean()\n","        ssim_val = ssim(protein_counts_norm.cpu().numpy(), reconstructed_protein_counts.cpu().numpy(), data_range=reconstructed_protein_counts.cpu().numpy().max() - reconstructed_protein_counts.cpu().numpy().min())\n","\n","        results_df = pd.DataFrame({\n","            'RMSE': [rmse],\n","            'Pearson Correlation': [avg_corr_pearson],\n","            'SSIM':ssim_val\n","        })\n","\n","        results_file_path = os.path.join(results_dir, f\"{tissue}_training_results.csv\")\n","        results_df.to_csv(results_file_path, index=False)\n","\n","        adata_rna_test = sc.AnnData(rna_test)\n","        sc.pp.normalize_total(adata_rna_test, target_sum=1e4)\n","        sc.pp.log1p(adata_rna_test)\n","        counts_norm = adata_rna_test[:,  adata_rna_train.var_names].X\n","        rna_counts_norm = torch.FloatTensor(counts_norm).to(device)\n","\n","        adata_protein_test = sc.AnnData(protein_test)\n","        sc.pp.normalize_total(adata_protein_test, target_sum=1e4)\n","        sc.pp.log1p(adata_protein_test)\n","        counts_norm = adata_protein_test.X\n","        protein_counts_norm = torch.FloatTensor(counts_norm).to(device)\n","\n","        combined_data = torch.cat([rna_counts_norm, torch.zeros(rna_counts_norm.shape[0], protein_counts_norm.shape[1]).to(device)], dim=1)\n","        reconstructed_data, mean, logvar = model(combined_data)\n","        reconstructed_protein_counts = reconstructed_data[:, rna_counts_norm.shape[1]:]\n","\n","        rmse = np.sqrt(mean_squared_error(protein_counts_norm.cpu().numpy(), reconstructed_protein_counts.cpu().numpy()))\n","        pcc = pd.DataFrame(protein_counts_norm.cpu().numpy()).corrwith(pd.DataFrame(reconstructed_protein_counts.cpu().numpy()), axis=1, method='pearson')\n","        avg_corr_pearson = pcc.mean()\n","        ssim_val = ssim(protein_counts_norm.cpu().numpy(), reconstructed_protein_counts.cpu().numpy(), data_range=reconstructed_protein_counts.cpu().numpy().max() - reconstructed_protein_counts.cpu().numpy().min())\n","\n","        results_df = pd.DataFrame({\n","            'RMSE': [rmse],\n","            'Pearson Correlation': [avg_corr_pearson],\n","            'SSIM':ssim_val\n","        })\n","\n","    results_file_path = os.path.join(results_dir, f\"{tissue}_results.csv\")\n","    results_df.to_csv(results_file_path, index=False)\n","\n","    print(f\"Processed {tissue} successfully.\")\n",""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OZRLoMqei95l","outputId":"221ee496-9c52-4d09-efc4-e62c3f3dcc79"},"outputs":[{"name":"stdout","output_type":"stream","text":["(1710, 23900)\n","(1710, 231)\n","(1691, 15487)\n","(1691, 284)\n","(2500, 28279)\n","(2500, 284)\n","(2494, 20237)\n","(2494, 284)\n","(2492, 28418)\n","(2492, 284)\n","(2419, 23751)\n","(2419, 200)\n","(902, 20445)\n","(902, 200)\n","(2037, 19469)\n","(2037, 200)\n","(1303, 19924)\n","(1303, 200)\n"]}],"source":["tissues= ['humanGBM', 'humanskin', 'humanthymus', 'humanspleen', 'humantonsil', 'mousekidney', 'mouseintestine', 'mousecolon', 'mousespleen']\n","\n","for tissue in tissues:\n","    rna_data = None\n","    protein_data = None\n","\n","    for filename in os.listdir(data_dir):\n","        file_path = os.path.join(data_dir, filename)\n","        if tissue in filename and filename.endswith(\"RNA.tsv.gz\"):\n","            rna_data = pd.read_csv(file_path, sep=\"\\t\")\n","        elif tissue in filename and filename.endswith(\"protein.tsv.gz\"):\n","            protein_data = pd.read_csv(file_path, sep=\"\\t\")\n","\n","    print(rna_data.shape)\n","    print(protein_data.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"57CADseXi95m"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"base"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}